{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA to SYCL with Buffers and Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` sh\n",
    "BUILD:\n",
    "cd src\n",
    "./scripts/alcf/sycl.sh\n",
    "cd build_sycl_${USER} # We can change this\n",
    "make\n",
    "cd bin\n",
    "./raja-perf.exe -od output -k <DAXPY/LTIMES> -v <Base_Sycl/RAJA_Sycl>\n",
    "# -od: directory for output\n",
    "# -k: Kernels to run via pattern match\n",
    "# -v: Variant to run (Base, RAJA / SYCL,CUDA,OpenMP), not all are built\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Point\n",
    "### Existing CUDA code\n",
    "\n",
    "```c\n",
    "namespace rajaperf\n",
    "{\n",
    "namespace basic\n",
    "{\n",
    "\n",
    "  //\n",
    "  // Define thread block size for CUDA execution\n",
    "  //\n",
    "  const size_t block_size = 256;\n",
    "\n",
    "\n",
    "#define DAXPY_DATA_SETUP_CUDA \\\n",
    "  allocAndInitCudaDeviceData(x, m_x, iend); \\\n",
    "  allocAndInitCudaDeviceData(y, m_y, iend);\n",
    "\n",
    "#define DAXPY_DATA_TEARDOWN_CUDA \\\n",
    "  getCudaDeviceData(m_y, y, iend); \\\n",
    "  deallocCudaDeviceData(x); \\\n",
    "  deallocCudaDeviceData(y);\n",
    "\n",
    "__global__ void daxpy(Real_ptr y, Real_ptr x,\n",
    "                      Real_type a,\n",
    "                      Index_type iend)\n",
    "{\n",
    "   Index_type i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "   if (i < iend) {\n",
    "     DAXPY_BODY;\n",
    "   }\n",
    "}\n",
    "\n",
    "\n",
    "void DAXPY::runCudaVariant(VariantID vid)\n",
    "{\n",
    "  const Index_type run_reps = getRunReps();\n",
    "  const Index_type ibegin = 0;\n",
    "  const Index_type iend = getRunSize();\n",
    "\n",
    "  DAXPY_DATA_SETUP;\n",
    "\n",
    "  if ( vid == Base_CUDA ) {\n",
    "\n",
    "    DAXPY_DATA_SETUP_CUDA;\n",
    "\n",
    "    startTimer();\n",
    "    for (RepIndex_type irep = 0; irep < run_reps; ++irep) {\n",
    "\n",
    "      const size_t grid_size = RAJA_DIVIDE_CEILING_INT(iend, block_size);\n",
    "      daxpy<<<grid_size, block_size>>>( y, x, a,\n",
    "                                        iend );\n",
    "\n",
    "    }\n",
    "    stopTimer();\n",
    "\n",
    "    DAXPY_DATA_TEARDOWN_CUDA;\n",
    "\n",
    "  } else if ( vid == RAJA_CUDA ) {\n",
    "\n",
    "    DAXPY_DATA_SETUP_CUDA;\n",
    "\n",
    "    startTimer();\n",
    "    for (RepIndex_type irep = 0; irep < run_reps; ++irep) {\n",
    "\n",
    "      RAJA::forall< RAJA::cuda_exec<block_size, true /*async*/> >(\n",
    "        RAJA::RangeSegment(ibegin, iend), [=] __device__ (Index_type i) {\n",
    "        DAXPY_BODY;\n",
    "      });\n",
    "\n",
    "    }\n",
    "    stopTimer();\n",
    "\n",
    "    DAXPY_DATA_TEARDOWN_CUDA;\n",
    "\n",
    "  } else {\n",
    "     std::cout << \"\\n  DAXPY : Unknown Cuda variant id = \" << vid << std::endl;\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run DAXPY, maybe just sequential version?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup\n",
    "\n",
    "The `DAXPY_DATA_SETUP_CUDA` macro calls `allocAndInitCudaDeviceData` which is used to simplify the memory calls.\n",
    "\n",
    "```c\n",
    "  cudaMalloc( (void**)&dptr,\n",
    "              len * sizeof(typename std::remove_pointer<T>::type) );\n",
    "              \n",
    "  cudaMemcpy( dptr, hptr,\n",
    "              len * sizeof(typename std::remove_pointer<T>::type),\n",
    "              cudaMemcpyHostToDevice );\n",
    "                          \n",
    "```\n",
    "\n",
    "With SYCL we are able to use implicit memory management using `sycl::buffer` and `sycl::accessor`.  We are able to declare a buffer with attached source data.  For the above example `allocAndInitCudaDeviceData(x, m_x, iend);`, we will declare a buffer with `m_x` as our source data and `iend` our length.\n",
    "\n",
    "```c\n",
    "  sycl::buffer<Real_type> d_x { m_x, iend };\n",
    "```\n",
    "\n",
    "Note that this does not attach memory to a specific device.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel \n",
    "\n",
    "The CUDA kernel is defined within our namespace\n",
    "```c\n",
    "__global__ void daxpy(Real_ptr y, Real_ptr x,\n",
    "                      Real_type a,\n",
    "                      Index_type iend)\n",
    "{\n",
    "   Index_type i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "   if (i < iend) {\n",
    "     DAXPY_BODY;\n",
    "   }\n",
    "}\n",
    "```\n",
    "In SYCL we can write our kernel inline using a lambda.\n",
    "```c\n",
    "  [=] (sycl::item<1> item ) {\n",
    "\n",
    "    Index_type i = item.get_id(0);\n",
    "    DAXPY_BODY\n",
    "\n",
    "  });\n",
    "```\n",
    "\n",
    "Note that we use the `sycl::item` to access our iteration space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Launch\n",
    "The CUDA kernel launch is defining a grid size and block size.\n",
    "```c\n",
    "      const size_t grid_size = RAJA_DIVIDE_CEILING_INT(iend, block_size);\n",
    "      daxpy<<<grid_size, block_size>>>( y, x, a,\n",
    "                                        iend );\n",
    "```\n",
    "For now we will leave this to the SYCL runtime and instead pass in our global range.  This is given to the `parallel_for` as `sycl::range<1>(iend)`.  The template parameter defines the number of dimensions, 1.\n",
    "```c\n",
    "  qu.submit([&] (sycl::handler& h) {\n",
    "    auto x = d_x.get_access<sycl::access::mode::read>(h);\n",
    "    auto y = d_y.get_access<sycl::access::mode::read_write>(h);\n",
    "\n",
    "    h.parallel_for(sycl::range<1>(iend), \n",
    "      // Here is where we use the above lambda\n",
    "      [=] (sycl::item<1> item ) {\n",
    "\n",
    "        Index_type i = item.get_id(0);\n",
    "        DAXPY_BODY\n",
    "\n",
    "    });\n",
    "  });\n",
    "```\n",
    "Using our `qu` we submit the accessors used by our kernel along with the `parallel_for`. The accessors, `auto x = d_x.get_access<sycl::access::mode::read>(h);`, tell the runtime what data is needed by our kernel and how it will be used, eg. `read_write`. This enables us to manage our memory implicitely.  The `qu.submit` submits asynchronously and returns a `sycl::event`.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Teardown\n",
    "\n",
    "Before the data moves back to the host, we want to finish all of our asynchronous execution.\n",
    "```c\n",
    "  qu.wait();\n",
    "```\n",
    "In CUDA we call `getCudaDeviceData` and `deallocCudaDeviceData` which are wrappers for:\n",
    "```c\n",
    "  cudaMemcpy( hptr, dptr,\n",
    "              len * sizeof(typename std::remove_pointer<T>::type),\n",
    "              cudaMemcpyDeviceToHost );\n",
    "  // and\n",
    "  cudaFree( dptr );\n",
    "              \n",
    "```\n",
    "When using buffers in SYCl we allow the buffer to fall out of scope, triggering a copy back to the source data location.\n",
    "\n",
    "```c\n",
    "{ // Scope for our buffer\n",
    "  sycl::buffer<type> buf(host_data, len)\n",
    "  /* Do our work\n",
    "   / Update buf via accessors\n",
    "   / Finish our work */\n",
    "} // Trigger data movement back to host_data\n",
    "```\n",
    "\n",
    "There is support for changing where the data is written back to, or triggering an update before the buffer falls out of scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```c\n",
    "#include \"DAXPY.hpp\"\n",
    "\n",
    "#include \"RAJA/RAJA.hpp\"\n",
    "\n",
    "#if defined(RAJA_ENABLE_SYCL)\n",
    "\n",
    "#include \"common/SyclDataUtils.hpp\"\n",
    "\n",
    "#include <iostream>\n",
    "\n",
    "namespace rajaperf\n",
    "{\n",
    "namespace basic\n",
    "{\n",
    "\n",
    "  //\n",
    "  // Define thread block size for SYCL execution\n",
    "  //\n",
    "  const size_t block_size = 256; // We could query our device for this\n",
    "\n",
    "#define DAXPY_DATA_SETUP_SYCL \\\n",
    "  sycl::buffer<Real_type> d_x { m_x, iend }; \\\n",
    "  sycl::buffer<Real_type> d_y { m_y, iend) }; \\\n",
    "\n",
    "\n",
    "#define DAXPY_DATA_TEARDOWN_SYCL \\\n",
    " // Nothing to do here\n",
    "\n",
    "void DAXPY::runSyclVariant(VariantID vid)\n",
    "{\n",
    "  const Index_type run_reps = getRunReps();\n",
    "  const Index_type ibegin = 0;\n",
    "  const Index_type iend = getRunSize();\n",
    "\n",
    "  DAXPY_DATA_SETUP; // This sets up our host data. m_x, m_y.\n",
    "\n",
    "  if ( vid == Base_SYCL ) {\n",
    "    { // Create a scope for our buffers\n",
    "\n",
    "      DAXPY_DATA_SETUP_SYCL;\n",
    "\n",
    "      startTimer();\n",
    "      for (RepIndex_type irep = 0; irep < run_reps; ++irep) {\n",
    "\n",
    "        qu.submit([&] (sycl::handler& h) {\n",
    "          auto x = d_x.get_access<sycl::access::mode::read>(h);\n",
    "          auto y = d_y.get_access<sycl::access::mode::read_write>(h);\n",
    "\n",
    "          h.parallel_for(sycl::range<1>(iend), [=] (sycl::item<1> item ) {\n",
    "\n",
    "            Index_type i = item.get_id(0);\n",
    "            DAXPY_BODY\n",
    "\n",
    "          });\n",
    "        });\n",
    "      }\n",
    "      qu.wait(); // Wait for computation to finish before stopping timer\n",
    "      stopTimer();\n",
    "     \n",
    "    } // End of buffer scope\n",
    "\n",
    "    DAXPY_DATA_TEARDOWN_SYCL;\n",
    " \n",
    "  } else if ( vid == RAJA_SYCL ) {\n",
    "\n",
    "  // We will do this later\n",
    "\n",
    "  } else {\n",
    "     std::cout << \"\\n  DAXPY : Unknown Sycl variant id = \" << vid << std::endl;\n",
    "  }\n",
    "\n",
    "}\n",
    "\n",
    "} // end namespace basic\n",
    "} // end namespace rajaperf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Run It !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
